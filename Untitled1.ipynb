{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Data/ace_2000.csv', header= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset.groupby(['doy'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'doy', 'hr', 'min', 'Np', 'Tp', 'Vp', 'B_gsm_x', 'B_gsm_y',\n",
       "       'B_gsm_z', 'Bt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = pd.read_csv('./Data/ace_2000_kp.csv', header= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'kp_0h', 'kp_3h', 'kp_6h', 'kp_9h', 'kp_12h', 'kp_15h',\n",
       "       'kp_18h', 'kp_21h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp['kp_av']= (kp[kp.keys()[1]] + kp[kp.keys()[2]] + kp[kp.keys()[3]]+ kp[kp.keys()[4]]++ kp[kp.keys()[5]]+ kp[kp.keys()[6]]++ kp[kp.keys()[7]]+ kp[kp.keys()[8]])/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp['kp'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,365) :\n",
    "    if kp['kp_av'][x]>=5 :\n",
    "        kp['kp'][x] = 1\n",
    "    elif kp['kp_av'][x]<5 :\n",
    "        kp['kp'][x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kp_0h</th>\n",
       "      <th>kp_3h</th>\n",
       "      <th>kp_6h</th>\n",
       "      <th>kp_9h</th>\n",
       "      <th>kp_12h</th>\n",
       "      <th>kp_15h</th>\n",
       "      <th>kp_18h</th>\n",
       "      <th>kp_21h</th>\n",
       "      <th>kp_av</th>\n",
       "      <th>kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2000-06-08</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2000-07-15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2000-08-11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  kp_0h  kp_3h  kp_6h  kp_9h  kp_12h  kp_15h  kp_18h  kp_21h  \\\n",
       "144  2000-05-24      7      7      6      6       4       4       5       4   \n",
       "159  2000-06-08      3      4      4      7       7       6       5       4   \n",
       "196  2000-07-15      4      4      5      5       6       9       9       9   \n",
       "223  2000-08-11      6      6      7      6       4       4       4       5   \n",
       "224  2000-08-12      5      7      8      7       7       7       5       4   \n",
       "278  2000-10-05      5      7      7      7       7       6       4       4   \n",
       "\n",
       "     kp_av  kp  \n",
       "144  5.375   1  \n",
       "159  5.000   1  \n",
       "196  6.375   1  \n",
       "223  5.250   1  \n",
       "224  6.250   1  \n",
       "278  5.875   1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp[kp['kp_av']>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kp_0h</th>\n",
       "      <th>kp_3h</th>\n",
       "      <th>kp_6h</th>\n",
       "      <th>kp_9h</th>\n",
       "      <th>kp_12h</th>\n",
       "      <th>kp_15h</th>\n",
       "      <th>kp_18h</th>\n",
       "      <th>kp_21h</th>\n",
       "      <th>kp_av</th>\n",
       "      <th>kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2000-06-08</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2000-07-15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2000-08-11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  kp_0h  kp_3h  kp_6h  kp_9h  kp_12h  kp_15h  kp_18h  kp_21h  \\\n",
       "144  2000-05-24      7      7      6      6       4       4       5       4   \n",
       "159  2000-06-08      3      4      4      7       7       6       5       4   \n",
       "196  2000-07-15      4      4      5      5       6       9       9       9   \n",
       "223  2000-08-11      6      6      7      6       4       4       4       5   \n",
       "224  2000-08-12      5      7      8      7       7       7       5       4   \n",
       "278  2000-10-05      5      7      7      7       7       6       4       4   \n",
       "\n",
       "     kp_av  kp  \n",
       "144  5.375   1  \n",
       "159  5.000   1  \n",
       "196  6.375   1  \n",
       "223  5.250   1  \n",
       "224  6.250   1  \n",
       "278  5.875   1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp[kp['kp']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['kp']= kp['kp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()\n",
    "data=data.drop(['year','hr','min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "x_data=data.iloc[:,[1,2,3,4,5,6,7]]\n",
    "y_data=data.iloc[:,[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=x_train.values.tolist()\n",
    "# x_train=x_test.values.tolist()\n",
    "# y_train=y_train.values.tolist()\n",
    "# y_test=y_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 7])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal(shape=[7, 512]))\n",
    "b1 = tf.Variable(tf.random_normal(shape=[512])) \n",
    "net = tf.matmul(X, W1) + b1\n",
    "net = tf.nn.sigmoid(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal(shape=[512, 1]))\n",
    "b2 = tf.Variable(tf.random_normal(shape=[1]))\n",
    "prediction = tf.matmul(net, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(Y - prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.expand_dims(x_train,2)\n",
    "# np.expand_dims(y_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for epoch_index in range(epochs):\n",
    "    sess.run(train_op, feed_dict={X: x_train, Y: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50/50, train loss: 0.4840, test loss: 0.2145\n"
     ]
    }
   ],
   "source": [
    "    loss_value_train = sess.run(loss, feed_dict={X: x_train, Y: y_train})\n",
    "    loss_value_test = sess.run(loss, feed_dict={X: x_test, Y: y_test})     \n",
    "    print('epoch: {}/{}, train loss: {:.4f}, test loss: {:.4f}'.format(\n",
    "        epoch_index+1, epochs, loss_value_train, loss_value_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 2) for Tensor 'Placeholder:0', which has shape '(?, 7)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3a2b6027cefd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m y_predict = sess.run(prediction, feed_dict={X: [\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m ]})\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[[8.182088]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[8.182088]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1157\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 2) for Tensor 'Placeholder:0', which has shape '(?, 7)'"
     ]
    }
   ],
   "source": [
    "y_predict = sess.run(prediction, feed_dict={X: [\n",
    "    [0,7]\n",
    "]})\n",
    "print(y_predict) #[[8.182088]]\n",
    "print(y_predict.flatten()) #[8.182088]\n",
    "print(y_predict.flatten()[0]) #8.182088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.69\n",
      "테스트 세트 정확도: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트 정확도: {:.2f}\".format(mlp.score(x_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.2f}\".format(mlp.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.992\n",
      "테스트 세트 정확도: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 세트 각 특성의 평균을 계산합니다.\n",
    "mean_on_train = x_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차를 계산합니다.\n",
    "std_on_train = x_train.std(axis=0)\n",
    "\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1인 데이터로 변환됩니다.\n",
    "x_train_scaled = (x_train - mean_on_train) / std_on_train\n",
    "# (훈련 데이터의 평균과 표준 편차를 이용해) 같은 변환을 테스트 세트에도 합니다.\n",
    "x_test_scaled = (x_test - mean_on_train) / std_on_train\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(x_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(x_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.992\n",
      "테스트 세트 정확도: 0.982\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=0)\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(x_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(x_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.992\n",
      "테스트 세트 정확도: 0.982\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(x_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(x_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     kp\n",
      "6     0\n",
      "160   0\n",
      "193   0\n",
      "291   0\n",
      "281   0\n",
      "..   ..\n",
      "319   0\n",
      "101   0\n",
      "262   0\n",
      "88    0\n",
      "310   0\n",
      "\n",
      "[110 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x278e423a1c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 45769 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 50976 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 45787 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 45769 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 50976 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 45787 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 51077 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47141 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 53945 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49457 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 51077 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47141 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 53945 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\sun\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49457 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
    "# plt.yticks(range(30), cancer.feature_names)\n",
    "plt.xlabel(\"은닉 유닛\")\n",
    "plt.ylabel(\"입력 특성\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-aa833d8c536c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Np'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for i in data:\n",
    "    print(i['Np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 train + 74 test\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doy</th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bt</th>\n",
       "      <th>kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>-438.653974</td>\n",
       "      <td>91808.444444</td>\n",
       "      <td>-53.193733</td>\n",
       "      <td>3.417259</td>\n",
       "      <td>-2.051696</td>\n",
       "      <td>-0.429315</td>\n",
       "      <td>8.926744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>-345.121724</td>\n",
       "      <td>97156.592593</td>\n",
       "      <td>115.472659</td>\n",
       "      <td>2.514626</td>\n",
       "      <td>1.170886</td>\n",
       "      <td>-0.254579</td>\n",
       "      <td>3.932616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>-9999.900000</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>-108.657615</td>\n",
       "      <td>-1.250539</td>\n",
       "      <td>0.823637</td>\n",
       "      <td>2.152491</td>\n",
       "      <td>4.573345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>-413.563637</td>\n",
       "      <td>166464.074074</td>\n",
       "      <td>123.314889</td>\n",
       "      <td>-2.984663</td>\n",
       "      <td>1.163902</td>\n",
       "      <td>0.887573</td>\n",
       "      <td>4.839820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>355</td>\n",
       "      <td>-9999.900000</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>-654.376067</td>\n",
       "      <td>-2.118510</td>\n",
       "      <td>2.059189</td>\n",
       "      <td>-0.174103</td>\n",
       "      <td>4.128613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>-916.573008</td>\n",
       "      <td>111044.518519</td>\n",
       "      <td>-9.231059</td>\n",
       "      <td>3.331810</td>\n",
       "      <td>-5.916609</td>\n",
       "      <td>0.853361</td>\n",
       "      <td>10.487539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>-579.944476</td>\n",
       "      <td>107224.074074</td>\n",
       "      <td>-266.441259</td>\n",
       "      <td>-2.693090</td>\n",
       "      <td>4.981786</td>\n",
       "      <td>-0.095156</td>\n",
       "      <td>11.620312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>-471.961958</td>\n",
       "      <td>114177.185185</td>\n",
       "      <td>1.063030</td>\n",
       "      <td>-1.580902</td>\n",
       "      <td>2.017324</td>\n",
       "      <td>-0.358354</td>\n",
       "      <td>4.423503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>349</td>\n",
       "      <td>-394.172271</td>\n",
       "      <td>45858.740741</td>\n",
       "      <td>-54.914015</td>\n",
       "      <td>2.250239</td>\n",
       "      <td>-1.917088</td>\n",
       "      <td>0.194784</td>\n",
       "      <td>4.462888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>-1069.050989</td>\n",
       "      <td>38652.814815</td>\n",
       "      <td>-393.453652</td>\n",
       "      <td>1.901910</td>\n",
       "      <td>-2.260331</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>5.351856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doy           Np             Tp          Vp   B_gsm_x   B_gsm_y  \\\n",
       "341  342  -438.653974   91808.444444  -53.193733  3.417259 -2.051696   \n",
       "202  203  -345.121724   97156.592593  115.472659  2.514626  1.170886   \n",
       "75    76 -9999.900000  -10000.000000 -108.657615 -1.250539  0.823637   \n",
       "84    85  -413.563637  166464.074074  123.314889 -2.984663  1.163902   \n",
       "354  355 -9999.900000  -10000.000000 -654.376067 -2.118510  2.059189   \n",
       "..   ...          ...            ...         ...       ...       ...   \n",
       "71    72  -916.573008  111044.518519   -9.231059  3.331810 -5.916609   \n",
       "106  107  -579.944476  107224.074074 -266.441259 -2.693090  4.981786   \n",
       "270  271  -471.961958  114177.185185    1.063030 -1.580902  2.017324   \n",
       "348  349  -394.172271   45858.740741  -54.914015  2.250239 -1.917088   \n",
       "102  103 -1069.050989   38652.814815 -393.453652  1.901910 -2.260331   \n",
       "\n",
       "      B_gsm_z         Bt  kp  \n",
       "341 -0.429315   8.926744   0  \n",
       "202 -0.254579   3.932616   0  \n",
       "75   2.152491   4.573345   0  \n",
       "84   0.887573   4.839820   0  \n",
       "354 -0.174103   4.128613   0  \n",
       "..        ...        ...  ..  \n",
       "71   0.853361  10.487539   0  \n",
       "106 -0.095156  11.620312   0  \n",
       "270 -0.358354   4.423503   0  \n",
       "348  0.194784   4.462888   0  \n",
       "102  0.003719   5.351856   0  \n",
       "\n",
       "[292 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              Np             Tp           Vp   B_gsm_x   B_gsm_y   B_gsm_z  \\\n",
       " 153  -446.412916   41402.148148   -71.860652 -0.425401 -1.462679 -0.756883   \n",
       " 145  -373.913989   35628.770370   123.959452 -1.615001 -0.681753 -3.084957   \n",
       " 167  -724.058513  120285.037037  -295.298711 -3.576764  1.795737  1.819584   \n",
       " 169  -395.717759   68383.525926   -56.241370 -1.155922  3.092799 -1.382791   \n",
       " 106  -579.944476  107224.074074  -266.441259 -2.693090  4.981786 -0.095156   \n",
       " ..           ...            ...          ...       ...       ...       ...   \n",
       " 71   -916.573008  111044.518519    -9.231059  3.331810 -5.916609  0.853361   \n",
       " 87  -6361.706870   35488.518519 -1072.080600 -3.494424  4.248213  1.227955   \n",
       " 59   -360.614993  114458.370370   166.394815 -0.398510  1.686310  1.149333   \n",
       " 303  -617.289280   39406.888889  -295.930452  5.046204 -7.186130 -0.559570   \n",
       " 103 -1574.183138   76424.444444  -147.942615 -4.386216  1.107667  0.024872   \n",
       " \n",
       "             Bt  \n",
       " 153   3.479558  \n",
       " 145   4.701841  \n",
       " 167   5.390798  \n",
       " 169   5.347323  \n",
       " 106  11.620312  \n",
       " ..         ...  \n",
       " 71   10.487539  \n",
       " 87    7.814697  \n",
       " 59    4.265376  \n",
       " 303  10.391031  \n",
       " 103   5.321737  \n",
       " \n",
       " [256 rows x 7 columns],\n",
       "               Np             Tp          Vp   B_gsm_x   B_gsm_y   B_gsm_z  \\\n",
       " 6    -345.141177   87342.074074  114.081622 -2.355798  1.781675  0.002706   \n",
       " 160  -538.522102   41924.362963  -47.043230 -8.995128  0.438513  2.681119   \n",
       " 193  -360.068413   32802.022222  107.288763 -7.043480  3.881935  4.794499   \n",
       " 291  -506.273001   90192.074074 -116.509474  4.587214 -0.975478  0.069413   \n",
       " 281 -9999.900000  -10000.000000   -3.260496  0.263252  0.868919 -0.272156   \n",
       " ..           ...            ...         ...       ...       ...       ...   \n",
       " 319  -988.514893   44593.629630 -636.042704  1.498476 -1.827770  0.808601   \n",
       " 101  -389.209478   89528.349371  -16.921184  2.400821 -2.509073 -2.157206   \n",
       " 262  -403.028496   48591.703704  184.426207  3.008491 -2.726624  0.420532   \n",
       " 88  -3612.786433   50416.444444  -44.654533 -1.880803  4.695887  3.358362   \n",
       " 310  -467.430724  120019.925926   45.432044 -0.533336  4.711210 -5.247433   \n",
       " \n",
       "             Bt  \n",
       " 6     4.388787  \n",
       " 160  10.120738  \n",
       " 193  10.040577  \n",
       " 291   5.954467  \n",
       " 281   3.158575  \n",
       " ..         ...  \n",
       " 319   3.994196  \n",
       " 101   5.254603  \n",
       " 262   6.865850  \n",
       " 88    8.190430  \n",
       " 310   9.508153  \n",
       " \n",
       " [110 rows x 7 columns],\n",
       "      kp\n",
       " 153   0\n",
       " 145   0\n",
       " 167   0\n",
       " 169   0\n",
       " 106   0\n",
       " ..   ..\n",
       " 71    0\n",
       " 87    0\n",
       " 59    0\n",
       " 303   0\n",
       " 103   0\n",
       " \n",
       " [256 rows x 1 columns],\n",
       "      kp\n",
       " 6     0\n",
       " 160   0\n",
       " 193   0\n",
       " 291   0\n",
       " 281   0\n",
       " ..   ..\n",
       " 319   0\n",
       " 101   0\n",
       " 262   0\n",
       " 88    0\n",
       " 310   0\n",
       " \n",
       " [110 rows x 1 columns])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-740376ec895c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    509\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=1500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doy</th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bt</th>\n",
       "      <th>kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>-360.068413</td>\n",
       "      <td>32802.022222</td>\n",
       "      <td>107.288763</td>\n",
       "      <td>-7.043480</td>\n",
       "      <td>3.881935</td>\n",
       "      <td>4.794499</td>\n",
       "      <td>10.040577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-386.317034</td>\n",
       "      <td>62054.592593</td>\n",
       "      <td>6.815941</td>\n",
       "      <td>-2.474451</td>\n",
       "      <td>2.498431</td>\n",
       "      <td>-0.301970</td>\n",
       "      <td>5.205880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-366.624239</td>\n",
       "      <td>56950.740741</td>\n",
       "      <td>-4.532037</td>\n",
       "      <td>2.780967</td>\n",
       "      <td>-1.115376</td>\n",
       "      <td>-1.242353</td>\n",
       "      <td>5.002225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>311</td>\n",
       "      <td>-467.430724</td>\n",
       "      <td>120019.925926</td>\n",
       "      <td>45.432044</td>\n",
       "      <td>-0.533336</td>\n",
       "      <td>4.711210</td>\n",
       "      <td>-5.247433</td>\n",
       "      <td>9.508153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>-359.706660</td>\n",
       "      <td>136321.703704</td>\n",
       "      <td>155.717489</td>\n",
       "      <td>-3.123366</td>\n",
       "      <td>2.081336</td>\n",
       "      <td>1.072681</td>\n",
       "      <td>5.376212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>184</td>\n",
       "      <td>-332.842285</td>\n",
       "      <td>26726.125926</td>\n",
       "      <td>12.647007</td>\n",
       "      <td>3.519974</td>\n",
       "      <td>-2.313450</td>\n",
       "      <td>1.239819</td>\n",
       "      <td>5.298206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>-9999.900000</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>-1084.569274</td>\n",
       "      <td>-3.394280</td>\n",
       "      <td>5.261413</td>\n",
       "      <td>4.220447</td>\n",
       "      <td>9.124738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>-424.299945</td>\n",
       "      <td>71467.481481</td>\n",
       "      <td>-58.960030</td>\n",
       "      <td>3.078330</td>\n",
       "      <td>-3.269777</td>\n",
       "      <td>-0.787766</td>\n",
       "      <td>6.447570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153</td>\n",
       "      <td>-330.505044</td>\n",
       "      <td>69930.296296</td>\n",
       "      <td>122.192556</td>\n",
       "      <td>1.103614</td>\n",
       "      <td>-0.776434</td>\n",
       "      <td>-0.114839</td>\n",
       "      <td>3.285490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>-328.327829</td>\n",
       "      <td>69339.777778</td>\n",
       "      <td>70.701652</td>\n",
       "      <td>1.917618</td>\n",
       "      <td>-2.544816</td>\n",
       "      <td>-1.832576</td>\n",
       "      <td>4.866420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>340</td>\n",
       "      <td>-1043.519496</td>\n",
       "      <td>28274.592593</td>\n",
       "      <td>-735.955615</td>\n",
       "      <td>-3.271767</td>\n",
       "      <td>1.724373</td>\n",
       "      <td>-0.307924</td>\n",
       "      <td>5.289861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doy           Np             Tp           Vp   B_gsm_x   B_gsm_y  \\\n",
       "193  194  -360.068413   32802.022222   107.288763 -7.043480  3.881935   \n",
       "33    34  -386.317034   62054.592593     6.815941 -2.474451  2.498431   \n",
       "15    16  -366.624239   56950.740741    -4.532037  2.780967 -1.115376   \n",
       "310  311  -467.430724  120019.925926    45.432044 -0.533336  4.711210   \n",
       "57    58  -359.706660  136321.703704   155.717489 -3.123366  2.081336   \n",
       "183  184  -332.842285   26726.125926    12.647007  3.519974 -2.313450   \n",
       "76    77 -9999.900000  -10000.000000 -1084.569274 -3.394280  5.261413   \n",
       "119  120  -424.299945   71467.481481   -58.960030  3.078330 -3.269777   \n",
       "152  153  -330.505044   69930.296296   122.192556  1.103614 -0.776434   \n",
       "126  127  -328.327829   69339.777778    70.701652  1.917618 -2.544816   \n",
       "339  340 -1043.519496   28274.592593  -735.955615 -3.271767  1.724373   \n",
       "\n",
       "      B_gsm_z         Bt  kp  \n",
       "193  4.794499  10.040577   0  \n",
       "33  -0.301970   5.205880   0  \n",
       "15  -1.242353   5.002225   0  \n",
       "310 -5.247433   9.508153   0  \n",
       "57   1.072681   5.376212   0  \n",
       "183  1.239819   5.298206   0  \n",
       "76   4.220447   9.124738   0  \n",
       "119 -0.787766   6.447570   0  \n",
       "152 -0.114839   3.285490   0  \n",
       "126 -1.832576   4.866420   0  \n",
       "339 -0.307924   5.289861   0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
